{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnvpt6RYgPw7oNxnF8LvxK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcfatbeard57/Hands-On-ML-Tensor-FLow/blob/main/Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MSJLsUE4BRc"
      },
      "source": [
        "Chapter 7 : Ensemble Learning and Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9naYVy2qzSz"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpbUVutBQwtk"
      },
      "source": [
        "Ensemble methods work best when the predictors are as independent\r\n",
        "from one another as possible. One way to get diverse classifiers\r\n",
        "is to train them using very different algorithms. This increases the\r\n",
        "chance that they will make very different types of errors, improving\r\n",
        "the ensembleâ€™s accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTHznkRTq33O"
      },
      "source": [
        "### Hard Voting\r\n",
        "Majority-vote classifier is a an classifier which aggregate the predictions of\r\n",
        "each classifier and predict the class that gets the most votes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWPt9DE13_yz"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\r\n",
        "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\r\n",
        "svm_clf = SVC(gamma=\"auto\", random_state=42)\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(\r\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\r\n",
        "    voting='hard')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90EYJZQWRH8W"
      },
      "source": [
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhYfJg9RKdb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    y_pred = clf.predict(X_test)\r\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlTgZf-squUk"
      },
      "source": [
        "### Soft voting.\r\n",
        "If all classifiers are able to estimate class probabilities (i.e., they have a **predict_proba() method**), then you can tell Scikit-Learn to predict the class with the\r\n",
        "highest class probability, averaged over all the individual classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRgcwm2BrbAH"
      },
      "source": [
        "Achieves higher performance than hard voting because it gives more\r\n",
        "weight to highly confident votes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF1IvmS3rmxP"
      },
      "source": [
        "\r\n",
        "replace voting=\"hard\" with voting=\"soft\" and ensure that all classifiers can estimate class probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo8qT06KRK29"
      },
      "source": [
        "# replace voting=\"hard\" with voting=\"soft\" and ensure that all classifiers can estimate class probabilities."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izfpcw38uGtZ"
      },
      "source": [
        "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\r\n",
        "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\r\n",
        "#svm with predict_proba() method\r\n",
        "svm_clf = SVC(gamma=\"auto\", probability=True, random_state=42)\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(\r\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\r\n",
        "    voting='soft')\r\n",
        "voting_clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    y_pred = clf.predict(X_test)\r\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQLJSJfbtH0-"
      },
      "source": [
        "## Bagging and Pasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcgSYIimtReQ"
      },
      "source": [
        "use the same training algorithm for every\r\n",
        "predictor, but to train them on different random subsets of the training set. When\r\n",
        "sampling is performed with replacement, this method is called bagging1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-tX7juPtctC"
      },
      "source": [
        "Once all predictors are trained, the ensemble can make a prediction for a new instance by simply aggregating the predictions of all predictors the most frequent prediction for classification, or the average for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5sAlESoto5m"
      },
      "source": [
        "Each individual\r\n",
        "predictor has a higher bias than if it were trained on the original training set, but\r\n",
        "aggregation reduces both bias and variance.\r\n",
        "\r\n",
        "ensemble has a **similar bias but a lower variance** than a single predictor trained on the\r\n",
        "original training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLe-PiTqrkrm"
      },
      "source": [
        "\r\n",
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "\r\n",
        "bag_clf = BaggingClassifier(\r\n",
        "    DecisionTreeClassifier(random_state=42), n_estimators=500,\r\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\r\n",
        "bag_clf.fit(X_train, y_train)\r\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjWxb0nXxZij"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wq-_GX7x8sS"
      },
      "source": [
        "Automatically performs soft voting if base classifier has can estimate class probabilities i.e. predict_proba() method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p23Iex1HxZUk"
      },
      "source": [
        "## Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok2cCLd_xsxx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}